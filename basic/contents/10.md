网络爬虫相关解析库的使用
---

### 解析库的引入

1. 之前基于正则，比较繁琐，出错率较高
2. 爬取信息大多基于html结构的web页面, 网页节点较多，各种层级关系

### 常见的Python解析库

1. `XPath`: 基于XML文档，包含html查找功能 [官方文档](https://lxml.de/api/index.html)
2. `Beautiful Soup` [官方文档]()
3. `PyQuery` [官方文档]()

### 关于 XPath 的使用

1）安装相关库

$ `pip3 install lxml`

2）模拟的将要被爬取的网页页面结构

```html
<!DOCTYPE html>
<html>
<head>
    <title>我的水果摊</title>
</head>
<body>
    <h3 id="title">我的水果</h3>
    <ul>
        <li class="item-0"><a href="http://www.test1.com">橘子</a></li>
        <li class="item-1 shop"><a href="http://www.test2.com">橙子</a></li>
        <li class="item-2"><a href="http://www.test3.com">苹果</a></li>
        <li class="item-3"><a href="http://www.test4.com">樱桃</a></li>
        <li class="item-4 shop"><a href="http://www.test5.com">梨子</a></li>
    </ul>
</body>
</html>
```

3）进行解析

```python
# 导入模块
from lxml import etree

# 读取html文件信息
f = open("./index.html",'r',encoding="utf-8")
content = f.read()
f.close()

# 解析HTML文档，返回根节点对象
html = etree.HTML(content)
#print(html)  # <Element html at 0x103534c88>

# 获取网页中所有标签并遍历输出标签名
result = html.xpath("//*")
for t in result:
    print(t.tag, end=" ")
#[html head title body h3 ul li a li a ...]
print()

# 获取节点
result = html.xpath("//li") # 获取所有li节点
result = html.xpath("//li/a") # 获取所有li节点下的所有直接a子节点
result = html.xpath("//ul//a") # 效果同上（ul下所有子孙节点）
result = html.xpath("//a/..") #获取所有a节点的父节点
print(result)

# 获取属性和文本内容
result = html.xpath("//li/a/@href") #获取所有li下所有直接子a节点的href属性值
result = html.xpath("//li/a/text()") #获取所有li下所有直接子a节点内的文本内容
print(result) #['橘子', '橙子', '苹果', '樱桃', '梨子']

result = html.xpath("//li/a[@class]/text()") #获取所有li下所有直接含有class属性子a节点内的文本内容
print(result) #['橘子', '苹果', '樱桃']

#获取所有li下所有直接含有class属性值为aa的子a节点内的文本内容
result = html.xpath("//li/a[@class='aa']/text()") 
print(result) #['苹果', '樱桃']

#获取class属性值中含有shop的li节点下所有直接a子节点内的文本内容
result = html.xpath("//li[contains(@class,'shop')]/a/text()") 
print(result) #['苹果', '樱桃']

# 按序选择
result = html.xpath("//li[1]/a/text()") # 获取每组li中的第一个li节点里面的a的文本
result = html.xpath("//li[last()]/a/text()") # 获取每组li中最后一个li节点里面的a的文本
result = html.xpath("//li[position()<3]/a/text()") # 获取每组li中前两个li节点里面的a的文本
result = html.xpath("//li[last()-2]/a/text()") # 获取每组li中倒数第三个li节点里面的a的文本
print(result) 

print("--"*30)
# 节点轴选择
result = html.xpath("//li[1]/ancestor::*") # 获取li的所有祖先节点
result = html.xpath("//li[1]/ancestor::ul") # 获取li的所有祖先中的ul节点
result = html.xpath("//li[1]/a/attribute::*") # 获取li中a节点的所有属性值
result = html.xpath("//li/child::a[@href='http://www.sohu.com']") #获取li子节点中属性href值的a节点
result = html.xpath("//body/descendant::a") # 获取body中的所有子孙节点a
print(result) 

result = html.xpath("//li[3]") #获取li中的第三个节点    
result = html.xpath("//li[3]/following::li") #获取第三个li节点之后所有li节点
result = html.xpath("//li[3]/following-sibling::*") #获取第三个li节点之后所有同级li节点
for v in result:
    print(v.find("a").text)


# 获取id属性为title的节点中的文本内容
print(html.xpath("//h3[@id='title']/text()")) #['我的水果']

# 获取li中所有超级链接a的信息
result = html.xpath("//li/a")
for t in result:
    # 通过xapth()二次解析结果
    #print(t.xpath("text()")[0], ':', t.xpath("@href")[0])
    # 效果同上，使用节点对象属性方法解析
    print(t.text, ':', t.get("href"))

'''
#结果:
橘子 : http://www.test1.com
橙子 : http://www.test2.com
苹果 : http://www.test3.com
樱桃 : http://www.test4.com
梨子 : http://www.test5.com
'''

'''
重点补充：）

HTML元素的属性：
    tag：元素标签名
    text：标签中间的文本
HTML元素的方法：
    find()    查找一个匹配的元素
    findall() 查找所有匹配的元素    
    get(key, default=None) 获取指定属性值
    items（）获取元素属性，作为序列返回
    keys（）获取属性名称列表
    value是（）将元素属性值作为字符串序列
'''
```
